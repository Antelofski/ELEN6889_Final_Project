{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d37223",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "                                                                                \r"
    }
   ],
   "source": [
    "# define the input and output paths of your bucket\n",
    "input_path = \"gs://dataproc-staging-us-central1-300388429198-ocbfs3ky/inputdata\"\n",
    "output_path = \"gs://dataproc-staging-us-central1-300388429198-ocbfs3ky/outputdata\"\n",
    "\n",
    "# read in the CSV file as a DataFrame\n",
    "df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"false\")\n",
    "    .schema(schema)\n",
    "    .load(input_path)\n",
    ")\n",
    "\n",
    "# define a user-defined function to check if a string is in English\n",
    "def is_english(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    try:\n",
    "        text.encode('ascii')\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# register the UDF\n",
    "is_english_udf = udf(is_english, BooleanType())\n",
    "# filter out non-English text\n",
    "df_filtered = df.filter(is_english_udf(df[\"text\"]))\n",
    "\n",
    "df_filtered = df.filter(col(\"location\").isNotNull() & col(\"likes\").isNotNull() & col(\"sentiment\").isNotNull())\n",
    "\n",
    "# group the remaining tweets by location and a 1-hour window with a sliding duration of 30 minutes\n",
    "likes_by_location_windowed = (\n",
    "    df_filtered\n",
    "    .groupBy(\n",
    "        window(col(\"timestamp\"), \"1 hour\", \"30 minutes\"),\n",
    "        col(\"location\")\n",
    "    )\n",
    "    .agg(sum(\"likes\").alias(\"total_likes\"))\n",
    "    .withColumn(\"window_start\", col(\"window.start\"))\n",
    "    .withColumn(\"window_end\", col(\"window.end\"))\n",
    "    .drop(\"window\")\n",
    ")\n",
    "\n",
    "# write the aggregated data to a CSV file on your bucket\n",
    "likes_by_location_windowed.write.mode(\"overwrite\").csv(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf79307",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}