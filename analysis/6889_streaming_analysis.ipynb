{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, BooleanType\n",
    "from pyspark.sql.functions import col, lit, sum, window, udf, when, avg\n",
    "import time\n",
    "\n",
    "# define the input and output paths of your bucket\n",
    "input_path = \"gs://6889nba/nba/\"\n",
    "output_path = \"gs://6889nba/output/\"\n",
    "\n",
    "# read in the CSV file as a DataFrame\n",
    "df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"false\")\n",
    "    .schema(schema)\n",
    "    .load(input_path)\n",
    ")\n",
    "\n",
    "# define a user-defined function to check if a string is in English\n",
    "def is_english(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    try:\n",
    "        text.encode('ascii')\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# register the UDF\n",
    "is_english_udf = udf(is_english, BooleanType())\n",
    "# filter out non-English text\n",
    "df_filtered = df.filter(is_english_udf(df[\"text\"]))\n",
    "\n",
    "df_filtered = df.filter(col(\"location\").isNotNull() & col(\"likes\").isNotNull() & col(\"sentiment\").isNotNull())\n",
    "\n",
    "# group the remaining tweets by location and a 1-hour window with a sliding duration of 30 minutes\n",
    "likes_by_location_windowed = (\n",
    "    df_filtered\n",
    "    .groupBy(\n",
    "        window(col(\"timestamp\"), \"1 hour\", \"30 minutes\"),\n",
    "        col(\"location\")\n",
    "    )\n",
    "    .agg(\n",
    "        sum(\"likes\").alias(\"total_likes\"),\n",
    "        sum(when(col(\"sentiment\") == 1, 1).otherwise(0)).alias(\"count_sentiment_1\"),\n",
    "        sum(when(col(\"sentiment\") == 0, 1).otherwise(0)).alias(\"count_sentiment_0\"),\n",
    "        sum(when(col(\"sentiment\") == -1, 1).otherwise(0)).alias(\"count_sentiment_-1\"),\n",
    "        avg(col(\"sentiment\")).alias(\"average_sentiment\")\n",
    "    )\n",
    "    .withColumn(\"window_start\", col(\"window.start\"))\n",
    "    .withColumn(\"window_end\", col(\"window.end\"))\n",
    "    .drop(\"window\")\n",
    "    .orderBy(\"window_start\")\n",
    ")\n",
    "\n",
    "# write the aggregated data to a CSV file on your bucket\n",
    "likes_by_location_windowed.write.mode(\"overwrite\").csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}